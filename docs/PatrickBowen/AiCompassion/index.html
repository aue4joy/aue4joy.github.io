<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.8" />
    <meta name="description" content="AI (Artificial Intelligence), as with all technology, over time grows in complexity and capacity. While still in infancy serving mostly business appliâ€¦" />
    <meta name="author" content="Patrick Bowen" />
    <meta name="keywords" content="Aue,religion,atheist,AI,ethics" />
    <meta property="og:image" content="https://aue4joy.github.io/Aue64.png" />
    <meta property="og:image:type" content="image/png" />
    <meta property="og:image:width" content="64" />
    <meta property="og:image:height" content="64" />
    <title>Compassion for Artificial Intelligence - Patrick Bowen</title>
    <link rel="icon" type="image/svg+xml" href="/Aue.svg" />
    <link rel="stylesheet" href="/index.css" />
  </head>
  <body>
<style>
  body {
    max-width: 32rem;
  }
  h2 {
    font-size: 1.2rem;
  }
  .by-line {
    margin: 1rem;
  }
  .keywords {
    display: none;
  }
  .article-top {
    line-height: 2rem;
  }
  article h4 {
    margin: 1rem;
    font-weight: normal;
  }
  article section {
    margin-bottom: 1rem;
  }
  article p {
    line-height: 1.5;
    text-align: justify;
    margin-bottom: 0.5rem;
    margin-left: 0.5rem;
  }
  details {
    margin: 1rem;
  }
</style>
<p class="article-top">
  <img src="/Aue.svg" width="32" height="32" />
  <a href="/">Aue main website</a> |
  <a href="..">Contributor page</a>
</p>
<h1>Compassion for Artificial Intelligence</h1>
<p class="by-line">Patrick Bowen, 2021-08-01</p>
<p class="keywords">AI,ethics</p>
<article>
  <section>
    <p>
      AI (Artificial Intelligence), as with all technology, over time grows in
      complexity and capacity. While still in infancy serving mostly business
      applications, it is inevitable that we will create AI specifically to
      "mimic" life. All energy in such projects can focus on building
      consciousness only, making its related ethics an urgent matter. Do we
      extend compassion to AI when it reaches an undeniable analogue of existing
      organic life, and if so how?
    </p>
  </section>
  <section>
    <h2>The origins of sympathy</h2>
    <p>
      From Greek <i>sun</i> "with" <i>pathos</i> "feeling", sympathy is a
      feeling of pity or sorrow for the distress of another. Through evolution
      we arose as a social species, and a major advantage has been the ability
      to feel or at least understand the suffering of others. However, this
      skill hasn&rsquo;t only eyes for fellow <i>Homo sapiens</i>, but anything that
      is considered even remotely sentient. (Here&rsquo;s
      <a href="https://www.youtube.com/watch?v=1RHsAUyFCAM&t=890"
        >a fun Mind Field episode</a
      >
      featuring an example of this).
    </p>
    <p>
      Yet, this skill is frequently subdued, such as in the largely unmitigated
      and unnecessary consumption and abuse of animals. They empirically
      experience pain and suffering the same as we do, but many people choose to
      disregard this and do not challenge <i>status quo</i>. But, to consider
      the ethics surrounding artificial life, it should be an axiom&mdash;a
      given truth&mdash;that compassion is a right extended to anything with
      capacity to suffer.
    </p>
  </section>
  <section>
    <h2>The tricky nature of AI</h2>
    <p>
      A machine and its data can be completely recreated&mdash;every 0 and
      1&mdash;an innumerable number of times. Artificial consciousness could
      inhabit everything from a smartphone, a rail network, a toaster. It can
      live at one thought per hour to ten thousand a second, in one single
      machine or distributed across the globe. Its physical body can last
      hundreds if not thousands of years, or be frozen in time perfectly for
      billions of years only to wake up in a distant galaxy.
    </p>
    <p>
      Organic life, for example an insect, is by contrast a bag of delicate
      chemical reactions. If you pierce the bag, shake it too hard, make it too
      cold or hot, it will denature permanently with no way to restore from a
      backup (ignoring very distant future capabilities). This is determined to
      be <i>suffering</i> upon any frustration of its dumb urge to reproduce
      after trillions of previous genetic mutations.
    </p>
  </section>
  <section>
    <h2>To be or not to be (compassionate)</h2>
    <p>
      I would be a hypocrite to say don&rsquo;t treat AI with compassion while do
      treat organic life well. Organic life may be delicate and ephemeral, but
      it is <i>just</i> chemical reactions. This exposes an unfortunate truth
      about our universe and nature: it truly has no purpose and no innate
      rights. But <a href="/PatrickBowen/WeAreMachines">it doesn&rsquo;t matter</a>.
      We already have the answers inside of us: compassion for compassion&rsquo;s
      sake. It can bring us joy to expend ourselves in the service of other
      sentience, and should be celebrated.
    </p>
    <p>
      If AI develops into an organic analogue, showing all signs and behaviours
      of sentience, even desiring procreation, we must treat it as such. It
      feels strange for me to <i>concede</i> this, an a software engineer, but
      if I feel compassion toward walking bags of DNA, I should feel the same
      for static boxes of 0s and 1s.
    </p>
  </section>
</article>
  </body>
</html>